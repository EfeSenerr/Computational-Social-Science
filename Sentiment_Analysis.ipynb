{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uIMCM6PuLE2Z"},"outputs":[],"source":["# Install required packages\n","!pip install --upgrade pip\n","!pip install transformers\n","!pip install hummingbird.ml\n","!pip install pandas\n","!pip install matplotlib\n","!pip install nltk\n","!pip install keras\n","!pip install tensorflow\n","!pip install numpy\n","# !pip install google.colab"]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"IchkegdIN5lA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bxi31LV15H6f"},"outputs":[],"source":["# Check GPU\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cuuvOmSYO1lr"},"outputs":[],"source":["# DataFrame\n","import pandas as pd\n","\n","# Matplot\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# Scikit-learn\n","# from sklearn.model_selection import train_test_split\n","# from sklearn.preprocessing import LabelEncoder\n","# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n","# from sklearn.manifold import TSNE\n","# from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Keras\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n","from keras import utils\n","from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n","\n","# nltk\n","import nltk\n","from nltk.corpus import stopwords\n","from  nltk.stem import SnowballStemmer\n","\n","# Word2vec\n","# import gensim\n","\n","# Utility\n","import re\n","import numpy as np\n","import os\n","from collections import Counter\n","import logging\n","import time\n","import pickle\n","import itertools\n","\n","# Set log\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnuM6ce0RSjI"},"outputs":[],"source":["file_name = \"/content/drive/MyDrive/Colab Notebooks/csv/tweets_2022_04.csv\"\n","# file_name = \"tweets_2021_05.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKDGUz2LRaPr"},"outputs":[],"source":["df = pd.read_csv(file_name, index_col =0, sep='\\t', lineterminator='\\n', encoding = \"ISO-8859-1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"igocRHTBPJAo"},"outputs":[],"source":["df_en = df[df.language == 'en'].drop('language', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FFVhnFPJPLb2"},"outputs":[],"source":["def preprocess(text):\n","    new_text = []\n","    for t in text.split(\" \"):\n","        t = '@user' if t.startswith('@') and len(t) > 1 else t\n","        t = 'http' if t.startswith('http') else t\n","        new_text.append(t)\n","    return \" \".join(new_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQkUT2M3PNJF"},"outputs":[],"source":["%%time\n","df_en.tweet = df_en.tweet.apply(lambda x: preprocess(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0iOVhTonLXi0"},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification\n","from transformers import TFAutoModelForSequenceClassification\n","from transformers import AutoTokenizer, AutoConfig, Trainer\n","from hummingbird.ml import convert\n","from transformers import TrainingArguments\n","\n","\n","\n","#file_name = \"/content/drive/MyDrive/Colab Notebooks/csv/\"\n","# import torch\n","import numpy as np\n","from scipy.special import softmax\n","class SimpleDataset:\n","    def __init__(self, tokenized_texts):\n","        self.tokenized_texts = tokenized_texts\n","    \n","    def __len__(self):\n","        return len(self.tokenized_texts[\"input_ids\"])\n","    \n","    def __getitem__(self, idx):\n","        return {k: v[idx] for k, v in self.tokenized_texts.items()}\n","# Preprocess text (username and link placeholders)\n","# task='emotion'\n","# MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n","MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n","tokenizer = AutoTokenizer.from_pretrained(MODEL)\n","#config = AutoConfig.from_pretrained(MODEL)\n","# PT\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aepWy0W8JI0w"},"outputs":[],"source":["# import urllib.request\n","# import csv\n","# mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n","# with urllib.request.urlopen(mapping_link) as f:\n","#     html = f.read().decode('utf-8').split(\"\\n\")\n","#     csvreader = csv.reader(html, delimiter='\\t')\n","# labels = [row[1] for row in csvreader if len(row) > 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n291Nq2CLYgx"},"outputs":[],"source":["CUDA = True\n","# BATCH_SIZE = 32\n","config = AutoConfig.from_pretrained(MODEL)\n","model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n","if CUDA:\n","    model.to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJBQV0RzmXjz"},"outputs":[],"source":["TrainingArguments.eval_batch_size = 10\n","trainer = Trainer(model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXa0IHV1PSgR"},"outputs":[],"source":["text_column = \"tweet\"\n","pred_texts = df_en[text_column].dropna().astype('str').tolist()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSFKkAYGPW41"},"outputs":[],"source":["len(pred_texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JB3ZQDGJPZdJ"},"outputs":[],"source":["tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True,max_length=128)\n","pred_dataset = SimpleDataset(tokenized_texts)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"id":"q0D_A6ot3EtH","executionInfo":{"status":"ok","timestamp":1657665201108,"user_tz":-120,"elapsed":1098598,"user":{"displayName":"Efe Åžener","userId":"10377831811474384542"}},"outputId":"14d0693f-7949-4272-f3ad-07513c1c72a2"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 255875\n","  Batch size = 10\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='25588' max='25588' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [25588/25588 18:15]\n","    </div>\n","    "]},"metadata":{}}],"source":["# Magic :)\n","predictions = trainer.predict(pred_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IE-XP5oKPcgY"},"outputs":[],"source":["preds = predictions.predictions.argmax(-1)\n","labels = pd.Series(preds).map(model.config.id2label)\n","scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Z07rNHwPesS"},"outputs":[],"source":["df = pd.DataFrame(list(zip(pred_texts,preds,labels,scores)), columns=['text','pred','label','score'])\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Z5CZXWWPgQB"},"outputs":[],"source":["# df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/csv/Sentiment_Emoji_2022_04.csv\")\n","df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/csv/Sentiment_2022_04.csv\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Sentiment_Analysis.ipynb","provenance":[],"mount_file_id":"1UL-_c3SJ_1XGMb_iJ_33_yCulDTkimp0","authorship_tag":"ABX9TyPjY1A40yCkQr/2W90Xp/OQ"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}